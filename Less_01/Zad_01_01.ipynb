{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Осуществим предобработку данных с Твиттера, чтобы очищенные данные в дальнейшем\n",
        "использовать для задачи классификации. Данный датасет содержит негативные (label = 1)\n",
        "и нейтральные (label = 0) высказывания. Для работы объединим train_df и test_df.\n",
        "Задания:\n",
        "1. Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим\n",
        "функцию:\n",
        "* для того, чтобы найти все вхождения паттерна в тексте, необходимо\n",
        "использовать re.findall(pattern, input_txt)\n",
        "* для для замены @user на пробел, необходимо использовать re.sub()\n",
        "2. Изменим регистр твитов на нижний с помощью .lower().\n",
        "3. Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя\n",
        "apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в\n",
        "тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в\n",
        "качестве ключа (сокращенного слова), то заменить ключ на значение (полную\n",
        "версию слова).\n",
        "4. Заменим сокращения на их полные формы, используя short_word_dict. Для этого\n",
        "воспользуемся функцией, используемой в предыдущем пункте.\n",
        "5. Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict.\n",
        "Для этого воспользуемся функцией, используемой в предыдущем пункте.\n",
        "6. Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'.\n",
        "7. Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'.\n",
        "8. Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'.\n",
        "9. Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if\n",
        "len(w)>1]).\n",
        "10. Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый\n",
        "столбец 'tweet_token'.\n",
        "11. Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец\n",
        "'tweet_token_filtered' без стоп-слов.\n",
        "12. Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим\n",
        "столбец 'tweet_stemmed' после применения стемминга.\n",
        "13. Применим лемматизацию к токенам с помощью\n",
        "nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после\n",
        "применения лемматизации.\n",
        "14. Сохраним результат предобработки в pickle-файл."
      ],
      "metadata": {
        "id": "ow-6w59ffUEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import casual_tokenize, RegexpTokenizer, TreebankWordTokenizer\n",
        "from nltk.util import ngrams\n",
        "import pandas as pd\n",
        "import math"
      ],
      "metadata": {
        "id": "P6zpfxVVLs0E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import regex as re\n",
        "import html\n",
        "import nltk\n",
        "import pickle\n",
        "from dicts import apostrophe_dict, emoticon_dict, short_word_dict\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn7YE2M0NfgI",
        "outputId": "f0163678-7c4c-483a-952e-fae08845694b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STOP_WORDS = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "STEMMER = nltk.stem.PorterStemmer()\n",
        "LEMMATIZER = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "\n",
        "# Data load\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/NLP/Less_01/train_tweets.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/NLP/Less_01/test_tweets.csv')\n",
        "df = train_df.append(test_df, ignore_index = True, sort = False)"
      ],
      "metadata": {
        "id": "rpb8kOMqNeMn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.info())\n",
        "print(test_df.info())\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8pRWeTkP2Iv",
        "outputId": "e62bf906-2bdb-46bb-f8b4-0bb5d6e37a2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31962 entries, 0 to 31961\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      31962 non-null  int64 \n",
            " 1   label   31962 non-null  int64 \n",
            " 2   tweet   31962 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 749.2+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17197 entries, 0 to 17196\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      17197 non-null  int64 \n",
            " 1   tweet   17197 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 268.8+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 49159 entries, 0 to 49158\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      49159 non-null  int64  \n",
            " 1   label   31962 non-null  float64\n",
            " 2   tweet   49159 non-null  object \n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_from_dict(text, source_dict):\n",
        "    \n",
        "    \"\"\"Поиск по тексту, сопоставление токенов через dict, размещение по умолчанию, если не в dict\"\"\"\n",
        "    \n",
        "    return \" \".join([source_dict.get(word, word) for word in text.split()])\n",
        "\n",
        "\n",
        "def remove_onechar_tokens(text):\n",
        "    \n",
        "    \"\"\"Поиск по тексту, удаление односимвольных токенов\"\"\"\n",
        "    \n",
        "    return ' '.join([w for w in text.split() if len(w)>1])\n",
        "\n",
        "\n",
        "def filter_stop_words(tokens, stop_words=STOP_WORDS):\n",
        "    \n",
        "    \"\"\"Удалить стоп-слова из токенов\"\"\"\n",
        "    \n",
        "    return [token for token in tokens if token not in stop_words]\n",
        "    \n",
        "\n",
        "def stem_tokens(tokens, stemmer=STEMMER):\n",
        "    \n",
        "    \"\"\"Предварительная обработка стемминга\"\"\"\n",
        "    \n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "\n",
        "def lemmatize_tokens(tokens, lemmatizer=LEMMATIZER):\n",
        "    \n",
        "    \"\"\"Лемматизация\"\"\"\n",
        "    \n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    \n",
        "\n",
        "def preprocess(df,\n",
        "               src_col='tweet',\n",
        "               clean_col='clean_tweet',\n",
        "               token_col='tweet_token',\n",
        "               filter_col='tweet_token_filtered',\n",
        "               stemmed_col='tweet_stemmed',\n",
        "               lem_col='tweet_lemmatized'\n",
        "              ):\n",
        "  # 1. Удалить ссылки @user\n",
        "  df[clean_col] = df[src_col].apply(lambda x: re.sub(r'@[\\w]*','', x))\n",
        "    \n",
        "  # 2. Правильный регистр в нижнем регистре\n",
        "  df[clean_col] = df[clean_col].str.lower()\n",
        "    \n",
        "  # 3. Изменить апострофы\n",
        "  vfunc = np.vectorize(replace_from_dict)\n",
        "  df[clean_col] = vfunc(df[clean_col], apostrophe_dict)\n",
        "    \n",
        "  # 4. Продлить короткие слова\n",
        "  df[clean_col] = vfunc(df[clean_col], short_word_dict)\n",
        "    \n",
        "  # 5. Заменить смайлики\n",
        "  df[clean_col] = vfunc(df[clean_col], emoticon_dict)\n",
        "    \n",
        "  # 6. Заменить знаки препинания на пробелы\n",
        "  df[clean_col] = df[clean_col].apply(lambda x: re.sub(r'[^\\w\\s]','', x))\n",
        "    \n",
        "  # 7. Заменить специальные символы на пробелы\n",
        "  df[clean_col] = df[clean_col].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', ' ', x))\n",
        "    \n",
        "  # 8. Заменить цифры на пробелы\n",
        "  df[clean_col] = df[clean_col].apply(lambda x: re.sub(r'[^a-zA-Z]', ' ', x))\n",
        "    \n",
        "  # 9. Отбросьте односимвольное слово\n",
        "  vfunc = np.vectorize(remove_onechar_tokens)\n",
        "  df[clean_col] = vfunc(df[clean_col])\n",
        "    \n",
        "  # 10. Токенизировать текст\n",
        "  df[token_col] = df[clean_col].apply(lambda x:  nltk.tokenize.word_tokenize(x))\n",
        "    \n",
        "  # 11. Отфильтровать стоп-слова\n",
        "  stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "  df[filter_col] = df[token_col].apply(lambda x: filter_stop_words(x))\n",
        "    \n",
        "  # 12. Apply stemming\n",
        "  df[stemmed_col] = df[filter_col].apply(lambda x: stem_tokens(x))\n",
        "    \n",
        "  # 13. Лемматизировать\n",
        "  df[lem_col] = df[stemmed_col].apply(lambda x: lemmatize_tokens(x))\n",
        "    \n",
        "  return df"
      ],
      "metadata": {
        "id": "B2rBJlxfp0bM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "result = preprocess(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTxDrmTrhCbh",
        "outputId": "5b987649-71d5-40c8-bf6f-6d2a50d61fad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 22.3 s, sys: 173 ms, total: 22.5 s\n",
            "Wall time: 22.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "500gA1VUhGki",
        "outputId": "b162910e-d7c7-4a7d-94af-284a6684def8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \\\n",
              "0  when father is dysfunctional and is so selfish...   \n",
              "1  thanks for lyft credit cannot use cause they d...   \n",
              "2                                bihday your majesty   \n",
              "3    model love you take with you all the time in ur   \n",
              "4                  factsguide society now motivation   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [when, father, is, dysfunctional, and, is, so,...   \n",
              "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
              "2                            [bihday, your, majesty]   \n",
              "3  [model, love, you, take, with, you, all, the, ...   \n",
              "4             [factsguide, society, now, motivation]   \n",
              "\n",
              "                                tweet_token_filtered  \\\n",
              "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
              "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
              "2                                  [bihday, majesty]   \n",
              "3                      [model, love, take, time, ur]   \n",
              "4                  [factsguide, society, motivation]   \n",
              "\n",
              "                                       tweet_stemmed  \\\n",
              "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
              "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
              "2                                  [bihday, majesti]   \n",
              "3                      [model, love, take, time, ur]   \n",
              "4                        [factsguid, societi, motiv]   \n",
              "\n",
              "                                    tweet_lemmatized  \n",
              "0  [father, dysfunct, selfish, drag, kid, dysfunc...  \n",
              "1  [thank, lyft, credit, use, caus, offer, wheelc...  \n",
              "2                                  [bihday, majesti]  \n",
              "3                      [model, love, take, time, ur]  \n",
              "4                        [factsguid, societi, motiv]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0be88505-d59c-4107-8c62-c731ebb2950d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
              "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
              "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[bihday, your, majesty]</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "      <td>[bihday, majesti]</td>\n",
              "      <td>[bihday, majesti]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love you take with you all the time in ur</td>\n",
              "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
              "      <td>[model, love, take, time, ur]</td>\n",
              "      <td>[model, love, take, time, ur]</td>\n",
              "      <td>[model, love, take, time, ur]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "      <td>[factsguide, society, now, motivation]</td>\n",
              "      <td>[factsguide, society, motivation]</td>\n",
              "      <td>[factsguid, societi, motiv]</td>\n",
              "      <td>[factsguid, societi, motiv]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0be88505-d59c-4107-8c62-c731ebb2950d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0be88505-d59c-4107-8c62-c731ebb2950d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0be88505-d59c-4107-8c62-c731ebb2950d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Save to_pickle\n",
        "result.to_pickle(\"/content/drive/MyDrive/NLP/Less_01/df_processed.pkl\")"
      ],
      "metadata": {
        "id": "DraNaHAMhKxt"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}